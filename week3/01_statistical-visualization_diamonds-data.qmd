---
title: "stats viz diamond dataset"
author: "Jeremy Mikecz"
format: html
editor: visual
---

# Data Visualization in R: Building, Evaluating, and Refining Statistical Models (Diamonds dataset)

## Introduction

Welcome to this tutorial on data visualization for statistical modeling in R! In this notebook, we'll explore how to use visualization techniques to build, evaluate, and refine statistical models. We'll focus on using the tidyverse ecosystem (particularly ggplot2) and plotly for interactive visualizations.

By the end of this tutorial, you'll be able to:

1.  Create effective visualizations to explore relationships in your data
2.  Build statistical models based on your exploratory analysis
3.  Visualize model predictions and residuals
4.  Identify outliers and influential points
5.  Create interactive visualizations to communicate your findings

Let's get started!

## Setup

First, let's load the packages we'll need:

```{r setup}
#| message: false
#| warning: false

# Load required packages
library(tidyverse)  # For data manipulation and visualization
library(plotly)     # For interactive plots
library(broom)      # For tidying model outputs
library(GGally)     # For advanced plotting
library(modelr)     # For modeling functions
library(performance) # For model diagnostics

# Set a consistent theme for our plots
theme_set(theme_minimal(base_size = 12))
```

## Part 1: Exploratory Data Analysis

Before building any models, it's crucial to understand your data through visualization. Let's work with the `diamonds` dataset from ggplot2 as our example.

```{r load-data}
# Examine the diamonds dataset
glimpse(diamonds)

# Look at the first few rows
head(diamonds)

# Get summary statistics
summary(diamonds)
```

### Visualizing Distributions

Let's first look at the distribution of key variables:

```{r distributions}
# Histogram of diamond prices
ggplot(diamonds, aes(x = price)) +
  geom_histogram(bins = 50, fill = "steelblue", alpha = 0.7) +
  labs(title = "Distribution of Diamond Prices",
       x = "Price (USD)",
       y = "Count")

# Distribution of carat with density curve
ggplot(diamonds, aes(x = carat)) +
  geom_histogram(aes(y = ..density..), bins = 50, 
                 fill = "darkgreen", alpha = 0.7) +
  geom_density(color = "red", linewidth = 1) +
  labs(title = "Distribution of Diamond Carat Weights",
       x = "Carat",
       y = "Density")

# Convert to interactive plot with plotly
p <- ggplot(diamonds, aes(x = carat, fill = cut)) +
  geom_histogram(bins = 50, alpha = 0.7, position = "dodge") +
  labs(title = "Distribution of Carat by Cut Quality",
       x = "Carat",
       y = "Count")

ggplotly(p)
```

### Exploring Relationships Between Variables

Now let's examine relationships between variables:

```{r relationships}
# Scatterplot of price vs. carat
ggplot(diamonds, aes(x = carat, y = price, color = cut)) +
  geom_point(alpha = 0.5) +
  labs(title = "Diamond Price vs. Carat Weight",
       x = "Carat",
       y = "Price (USD)") +
  scale_color_viridis_d()

# Boxplots of price by cut
ggplot(diamonds, aes(x = cut, y = price, fill = cut)) +
  geom_boxplot() +
  labs(title = "Price Distribution by Cut",
       x = "Cut Quality",
       y = "Price (USD)") +
  theme(legend.position = "none")

# Create a sample for pair plots (full dataset is too large)
set.seed(123)
diamonds_sample <- diamonds %>% 
  sample_n(1000)

# Pair plot to see relationships among multiple variables
ggpairs(diamonds_sample, 
        columns = c("carat", "depth", "table", "price"),
        aes(color = cut, alpha = 0.5))
```

## Part 2: Building Statistical Models

Based on our exploratory analysis, let's build a model to predict diamond prices.

### Simple Linear Regression

Let's start with a simple linear model using carat to predict price:

```{r simple-model}
# Build a simple linear model
model1 <- lm(price ~ carat, data = diamonds)

# Summarize the model
summary(model1)

# Visualize the model
ggplot(diamonds, aes(x = carat, y = price)) +
  geom_point(alpha = 0.1) +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Linear Model: Price ~ Carat",
       x = "Carat",
       y = "Price (USD)")
```

The relationship appears non-linear. Let's try a log transformation:

```{r log-model}
# Build a model with log transformations
model2 <- lm(log(price) ~ log(carat), data = diamonds)

# Summarize the model
summary(model2)

# Create a new dataframe with predictions
diamonds_with_pred <- diamonds %>%
  mutate(
    log_price = log(price),
    log_carat = log(carat),
    pred_log_price = predict(model2),
    pred_price = exp(pred_log_price)
  )

# Visualize the log-transformed model
ggplot(diamonds_with_pred, aes(x = carat, y = price)) +
  geom_point(alpha = 0.1) +
  geom_line(aes(y = pred_price), color = "red", size = 1) +
  labs(title = "Non-Linear Model: log(Price) ~ log(Carat)",
       x = "Carat",
       y = "Price (USD)") +
  scale_x_log10() +
  scale_y_log10()
```

### Multiple Regression

Now let's build a more complex model that includes other predictors:

```{r multiple-regression}
# Build a multiple regression model
model3 <- lm(log(price) ~ log(carat) + cut + color + clarity, data = diamonds)

# Summarize the model
summary(model3)

# Compare model performance
models <- list(
  "Carat Only" = model1,
  "Log-transformed" = model2,
  "Full Model" = model3
)

# Create a comparison table
map_df(models, glance, .id = "model") %>%
  select(model, r.squared, adj.r.squared, AIC, BIC) %>%
  arrange(desc(adj.r.squared))
```

## Part 3: Model Evaluation and Diagnostics

Now that we've built models, let's evaluate them and look for potential issues.

### Residual Analysis

Residuals are the differences between observed values and values predicted by the model. Analyzing residuals helps identify model weaknesses.

```{r residuals}
# Add residuals to our data
model3_data <- augment(model3, data = diamonds) %>%
  mutate(
    .resid = exp(.fitted) - price  # Convert back to original scale
  )

# Residual plot
ggplot(model3_data, aes(x = .fitted, y = .resid)) +
  geom_point(alpha = 0.1) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  geom_smooth(se = FALSE, color = "blue") +
  labs(title = "Residuals vs. Fitted Values",
       x = "Fitted Values (log scale)",
       y = "Residuals")

# Histogram of residuals
ggplot(model3_data, aes(x = .resid)) +
  geom_histogram(bins = 50, fill = "steelblue", alpha = 0.7) +
  labs(title = "Distribution of Residuals",
       x = "Residual",
       y = "Count")

# QQ plot for residuals
ggplot(model3_data, aes(sample = .std.resid)) +
  geom_qq() +
  geom_qq_line(color = "red") +
  labs(title = "Normal Q-Q Plot of Standardized Residuals")
```

### Identifying Outliers and Influential Points

Let's identify potential outliers and influential points in our model:

```{r outliers}
# Calculate Cook's distance
model3_data <- model3_data %>%
  mutate(cooks_d = cooks.distance(model3))

# Plot Cook's distance
ggplot(model3_data, aes(x = 1:nrow(model3_data), y = cooks_d)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 4/nrow(model3_data), color = "red", linetype = "dashed") +
  labs(title = "Cook's Distance",
       x = "Observation Index",
       y = "Cook's Distance") +
  scale_y_log10()

# Identify potential outliers
potential_outliers <- model3_data %>%
  filter(cooks_d > 4/nrow(model3_data)) %>%
  arrange(desc(cooks_d))

# Look at the top 10 most influential points
head(potential_outliers, 10)

# Visualize outliers in the context of the data
ggplot(diamonds, aes(x = carat, y = price)) +
  geom_point(alpha = 0.1) +
  geom_point(data = head(potential_outliers, 100), 
             color = "red", alpha = 0.5) +
  labs(title = "Diamond Prices with Potential Outliers Highlighted",
       x = "Carat",
       y = "Price (USD)")
```

### Model Performance Visualization

Let's visualize how well our model performs across different subgroups:

```{r model-performance}
# Calculate prediction error by cut
prediction_error <- model3_data %>%
  group_by(cut) %>%
  summarize(
    mean_abs_error = mean(abs(.resid)),
    mean_rel_error = mean(abs(.resid / price)) * 100
  )

# Plot mean absolute error by cut
ggplot(prediction_error, aes(x = cut, y = mean_abs_error, fill = cut)) +
  geom_col() +
  labs(title = "Mean Absolute Error by Cut",
       x = "Cut Quality",
       y = "Mean Absolute Error") +
  theme(legend.position = "none")

# Plot mean relative error by cut
ggplot(prediction_error, aes(x = cut, y = mean_rel_error, fill = cut)) +
  geom_col() +
  labs(title = "Mean Relative Error by Cut (%)",
       x = "Cut Quality",
       y = "Mean Relative Error (%)") +
  theme(legend.position = "none")
```

## Part 4: Interactive Visualization with Plotly

Plotly allows us to create interactive visualizations that can be particularly useful for exploring model results:

```{r interactive}
# Create an interactive scatter plot with model predictions
p <- ggplot(diamonds_sample, aes(x = carat, y = price, color = cut, 
                              text = paste("Carat:", carat, 
                                          "<br>Price:", price,
                                          "<br>Cut:", cut))) +
  geom_point(alpha = 0.7) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Diamond Price vs. Carat with Linear Trend by Cut",
       x = "Carat",
       y = "Price (USD)")

# Convert to interactive plot
interactive_plot <- ggplotly(p, tooltip = "text")
interactive_plot

# Create an interactive residual plot
p2 <- ggplot(model3_data %>% sample_n(1000), 
            aes(x = .fitted, y = .std.resid, 
                color = cut,
                text = paste("Fitted:", round(exp(.fitted), 2),
                            "<br>Std. Residual:", round(.std.resid, 2),
                            "<br>Cut:", cut))) +
  geom_point(alpha = 0.7) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "Standardized Residuals vs. Fitted Values",
       x = "Fitted Values (log scale)",
       y = "Standardized Residuals")

# Convert to interactive plot
interactive_residuals <- ggplotly(p2, tooltip = "text")
interactive_residuals
```

## Part 5: Refining Models Based on Visualization Insights

Based on our visualizations, let's refine our model:

```{r refined-model}
# Create interaction terms based on our visualizations
model4 <- lm(log(price) ~ log(carat) * cut + color + clarity, data = diamonds)

# Summarize the refined model
summary(model4)

# Compare with previous model
anova(model3, model4)

# Check model performance metrics
performance::compare_performance(model3, model4)

# Visualize the predictions of the refined model
diamonds_sample$pred_model3 <- exp(predict(model3, newdata = diamonds_sample))
diamonds_sample$pred_model4 <- exp(predict(model4, newdata = diamonds_sample))

# Plot actual vs. predicted values for both models
p3 <- ggplot(diamonds_sample, aes(x = price)) +
  geom_point(aes(y = pred_model3, color = "Model 3"), alpha = 0.5) +
  geom_point(aes(y = pred_model4, color = "Model 4"), alpha = 0.5) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
  scale_color_manual(values = c("Model 3" = "blue", "Model 4" = "red")) +
  labs(title = "Actual vs. Predicted Prices",
       x = "Actual Price",
       y = "Predicted Price",
       color = "Model") +
  coord_equal()

ggplotly(p3)
```

## Conclusion

In this tutorial, we've covered:

1.  **Exploratory data analysis** using ggplot2 to understand the relationships in our data
2.  **Building statistical models** from simple to complex
3.  **Evaluating models** through residual analysis and performance metrics
4.  **Identifying outliers** and influential points
5.  **Creating interactive visualizations** with plotly
6.  **Refining models** based on insights from our visualizations

Visualization is an essential tool throughout the modeling process: - Before modeling, it helps you understand relationships in your data - During modeling, it helps you evaluate assumptions and performance - After modeling, it helps you communicate results and insights

Remember that the goal of visualization in the modeling context is not just to create pretty pictures, but to gain deeper insights into your data and models that might not be apparent from summary statistics alone.

## Exercise for Students

1.  Choose another dataset (e.g., `mpg` from ggplot2 or `mtcars` from base R)
2.  Create exploratory visualizations to understand the relationships in the data
3.  Build at least two different models to predict a variable of interest
4.  Evaluate your models using the visualization techniques we've covered
5.  Identify potential outliers and discuss how they might affect your models
6.  Create an interactive visualization to communicate your findings

Happy modeling and visualizing!
