---
title: "Statistical Visualization"
author: "Jeremy Mikecz"
format: html
editor: visual
---

# Data Visualization with R: From Exploration to Model Evaluation (Penguins dataset)

## Introduction

This notebook will guide you through the process of creating effective data visualizations using R, with a focus on the `tidyverse`, `ggplot2`, and `plotly` packages. We'll cover exploratory data analysis, building statistical models, visualizing those models, and identifying potential issues like outliers or assumption violations.

By the end of this notebook, you'll be able to: - Import and prepare data for visualization - Create static visualizations with `ggplot2` - Make interactive visualizations with `plotly` - Build statistical models and visualize their results - Identify outliers and evaluate model assumptions visually

Let's begin by setting up our environment and loading the necessary packages.

```{r setup}
#| message: false
#| warning: false

# Install packages if needed
# install.packages(c("tidyverse", "plotly", "broom", "GGally", "car", "performance"))

# Load required packages
library(tidyverse)  # For data manipulation and ggplot2
library(plotly)     # For interactive visualizations
library(broom)      # For tidying model output
library(GGally)     # For ggpairs and other multivariate plots
library(car)        # For diagnostic plots
library(performance) # For model checking
```

## Part 1: Data Import and Exploration

Let's start by importing a dataset. We'll use the Palmer Penguins dataset, which contains measurements for three penguin species.

```{r import-data}
# Load the penguins dataset
library(palmerpenguins)
data(penguins)

# Take a look at the data
glimpse(penguins)
```

### Data Cleaning and Preparation

Before visualization, we often need to clean and prepare our data.

```{r data-prep}
# Remove rows with missing values
penguins_clean <- penguins %>%
  drop_na()

# Create a summary of the data
penguins_summary <- penguins_clean %>%
  group_by(species, island, sex) %>%
  summarise(                 ##not summarize
    count = n(),
    mean_bill_length = mean(bill_length_mm),
    mean_bill_depth = mean(bill_depth_mm),
    mean_flipper_length = mean(flipper_length_mm),
    mean_body_mass = mean(body_mass_g),
    .groups = "drop"
  )

# View the summary
penguins_summary
```

## Part 2: Basic Visualizations with ggplot2

### Univariate Distributions

Let's start with some basic visualizations to understand the distributions of our variables.

```{r univariate-plots}
# Histogram of bill length
ggplot(penguins_clean, aes(x = bill_length_mm)) +
  geom_histogram(bins = 20, fill = "steelblue", color = "white") +
  labs(
    title = "Distribution of Bill Length",
    x = "Bill Length (mm)",
    y = "Count"
  ) +
  theme_minimal()

# Density plot by species
ggplot(penguins_clean, aes(x = bill_length_mm, fill = species)) +
  geom_density(alpha = 0.7) +
  labs(
    title = "Bill Length Distribution by Species",
    x = "Bill Length (mm)",
    y = "Density"
  ) +
  scale_fill_brewer(palette = "Set1") +
  theme_minimal()

# Boxplot of body mass by species and sex
ggplot(penguins_clean, aes(x = species, y = body_mass_g, fill = sex)) +
  geom_boxplot() +
  labs(
    title = "Body Mass by Species and Sex",
    x = "Species",
    y = "Body Mass (g)"
  ) +
  scale_fill_brewer(palette = "Pastel1") +
  theme_minimal()
```

### Bivariate Relationships

Now let's explore relationships between variables.

```{r bivariate-plots}
# Scatter plot of bill length vs. bill depth
ggplot(penguins_clean, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) +
  geom_point(alpha = 0.7) +
  labs(
    title = "Bill Length vs. Bill Depth",
    x = "Bill Length (mm)",
    y = "Bill Depth (mm)"
  ) +
  scale_color_brewer(palette = "Set1") +
  theme_minimal()

# Add a smoothing line to see trends
ggplot(penguins_clean, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) +
  geom_point(alpha = 0.7) +
  geom_smooth(method = "lm", se = TRUE) +
  labs(
    title = "Bill Length vs. Bill Depth with Trend Lines",
    x = "Bill Length (mm)",
    y = "Bill Depth (mm)"
  ) +
  scale_color_brewer(palette = "Set1") +
  theme_minimal()

# Correlation heatmap for numeric variables
penguins_numeric <- penguins_clean %>%
  select(bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g)

cor_matrix <- cor(penguins_numeric)

# Convert correlation matrix to long format for ggplot
cor_data <- as.data.frame(as.table(cor_matrix))
names(cor_data) <- c("Var1", "Var2", "Correlation")

ggplot(cor_data, aes(x = Var1, y = Var2, fill = Correlation)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0) +
  geom_text(aes(label = round(Correlation, 2)), color = "black", size = 3) +
  labs(title = "Correlation Matrix of Penguin Measurements") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

### Multivariate Visualization

Let's create more complex visualizations that show multiple variables at once.

```{r multivariate-plots}
# Scatter plot with multiple dimensions
ggplot(penguins_clean, aes(x = bill_length_mm, y = bill_depth_mm, 
                          color = species, size = body_mass_g)) +
  geom_point(alpha = 0.7) +
  facet_wrap(~island) +
  labs(
    title = "Bill Dimensions by Species, Island, and Body Mass",
    x = "Bill Length (mm)",
    y = "Bill Depth (mm)",
    size = "Body Mass (g)"
  ) +
  scale_color_brewer(palette = "Set1") +
  theme_minimal()

# Pairs plot for a quick overview of relationships
# This might take a moment to render
ggpairs(penguins_clean, 
        columns = c("bill_length_mm", "bill_depth_mm", "flipper_length_mm", "body_mass_g"),
        aes(color = species, alpha = 0.7),
        upper = list(continuous = "cor", combo = "box_no_facet"),
        lower = list(continuous = "smooth", combo = "dot_no_facet")) +
  labs(title = "Relationships Between Penguin Measurements") +
  theme_minimal()
```

## Part 3: Interactive Visualizations with Plotly

Now let's create some interactive visualizations using plotly.

```{r plotly-basic}
# Convert a ggplot to an interactive plotly visualization
p <- ggplot(penguins_clean, aes(x = bill_length_mm, y = bill_depth_mm, 
                               color = species, text = paste("Species:", species,
                                                            "<br>Island:", island,
                                                            "<br>Sex:", sex,
                                                            "<br>Body Mass:", body_mass_g, "g"))) +
  geom_point(alpha = 0.7) +
  labs(
    title = "Bill Length vs. Bill Depth",
    x = "Bill Length (mm)",
    y = "Bill Depth (mm)"
  ) +
  scale_color_brewer(palette = "Set1") +
  theme_minimal()

# Convert to interactive plot
ggplotly(p, tooltip = "text")
```

```{r plotly-advanced}
# Create a 3D scatter plot with plotly directly
plot_ly(penguins_clean, 
        x = ~bill_length_mm, 
        y = ~bill_depth_mm, 
        z = ~flipper_length_mm,
        color = ~species,
        symbol = ~sex,
        type = "scatter3d",
        mode = "markers",
        marker = list(size = 5, opacity = 0.7),
        hoverinfo = "text",
        text = ~paste("Species:", species,
                     "<br>Island:", island,
                     "<br>Sex:", sex,
                     "<br>Body Mass:", body_mass_g, "g")) %>%
  layout(
    title = "3D Visualization of Penguin Measurements",
    scene = list(
      xaxis = list(title = "Bill Length (mm)"),
      yaxis = list(title = "Bill Depth (mm)"),
      zaxis = list(title = "Flipper Length (mm)")
    )
  )
```

## Part 4: Building and Visualizing Statistical Models

Now let's build some statistical models and visualize their results.

### Linear Regression

```{r linear-model}
# Build a linear model predicting body mass from bill length and species
model1 <- lm(body_mass_g ~ bill_length_mm * species, data = penguins_clean)

# Summarize the model
summary(model1)

# Tidy the model output
model1_tidy <- tidy(model1, conf.int = TRUE)
model1_tidy

# Visualize the coefficients
ggplot(model1_tidy, aes(x = term, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  coord_flip() +
  labs(
    title = "Coefficient Estimates with 95% Confidence Intervals",
    x = NULL,
    y = "Estimate"
  ) +
  theme_minimal()

# Get fitted values and residuals
model1_aug <- augment(model1)

# Plot actual vs. fitted values
ggplot(model1_aug, aes(x = .fitted, y = body_mass_g, color = species)) +
  geom_point(alpha = 0.7) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(
    title = "Actual vs. Fitted Values",
    x = "Fitted Values",
    y = "Actual Body Mass (g)"
  ) +
  scale_color_brewer(palette = "Set1") +
  theme_minimal()

# Visualize the model with the data
ggplot(penguins_clean, aes(x = bill_length_mm, y = body_mass_g, color = species)) +
  geom_point(alpha = 0.7) +
  geom_smooth(method = "lm", se = TRUE) +
  labs(
    title = "Body Mass vs. Bill Length by Species",
    subtitle = "With Linear Regression Lines",
    x = "Bill Length (mm)",
    y = "Body Mass (g)"
  ) +
  scale_color_brewer(palette = "Set1") +
  theme_minimal()
```

### Identifying Outliers and Influential Points

```{r outliers}
# Add standardized residuals and Cook's distance
model1_aug <- model1_aug %>%
  mutate(
    std_resid = .std.resid,
    cooks_dist = cooks.distance(model1)
  )

# Plot standardized residuals
ggplot(model1_aug, aes(x = .fitted, y = std_resid, color = species)) +
  geom_point(alpha = 0.7) +
  geom_hline(yintercept = c(-2, 0, 2), linetype = c("dashed", "solid", "dashed")) +
  labs(
    title = "Standardized Residuals vs. Fitted Values",
    subtitle = "Points outside dashed lines may be outliers",
    x = "Fitted Values",
    y = "Standardized Residuals"
  ) +
  scale_color_brewer(palette = "Set1") +
  theme_minimal()

# Plot Cook's distance to identify influential points
ggplot(model1_aug, aes(x = seq_along(cooks_dist), y = cooks_dist, color = species)) +
  geom_point(alpha = 0.7) +
  geom_hline(yintercept = 4/nrow(penguins_clean), linetype = "dashed") +
  labs(
    title = "Cook's Distance for Each Observation",
    subtitle = "Points above dashed line may be influential",
    x = "Observation Index",
    y = "Cook's Distance"
  ) +
  scale_color_brewer(palette = "Set1") +
  theme_minimal()

# Identify potential outliers
potential_outliers <- model1_aug %>%
  filter(abs(std_resid) > 2 | cooks_dist > 4/nrow(penguins_clean)) %>%
  arrange(desc(cooks_dist))

# Display potential outliers
head(potential_outliers)
```

### Model Diagnostics

```{r model-diagnostics}
# Create diagnostic plots
par(mfrow = c(2, 2))
plot(model1)
par(mfrow = c(1, 1))

# Use the performance package for model checking
# install.packages("see")
check_model(model1)  #may prompt you to install `see` package

# Visualize residuals distribution
ggplot(model1_aug, aes(x = .resid)) +
  geom_histogram(bins = 20, fill = "steelblue", color = "white") +
  labs(
    title = "Distribution of Residuals",
    x = "Residuals",
    y = "Count"
  ) +
  theme_minimal()

# QQ plot for residuals
ggplot(model1_aug, aes(sample = .resid)) +
  stat_qq() +
  stat_qq_line() +
  labs(
    title = "Q-Q Plot of Residuals",
    x = "Theoretical Quantiles",
    y = "Sample Quantiles"
  ) +
  theme_minimal()
```

### If checkmodel() lags, try running individual diagnostic functions:

```{r}
# Instead of check_model(), use individual diagnostic functions
library(performance)

# Check for normality of residuals
check_normality(model1)

# Check for heteroscedasticity
check_heteroscedasticity(model1)

# Check for multicollinearity
check_collinearity(model1)

# Or use base R diagnostic plots which are faster
par(mfrow = c(2, 2))
plot(model1)
par(mfrow = c(1, 1))
```

or sample the data:

```{r fig.height=40}
# Create a smaller dataset if your original is large
set.seed(123)
penguins_sample <- penguins_clean %>% 
  sample_n(min(nrow(penguins_clean), 200))

# Fit model on sample
model1_sample <- lm(body_mass_g ~ bill_length_mm * species, data = penguins_sample)

# Check model on sample
check_model(model1_sample)
```

## Part 5: Advanced Modeling and Visualization

Let's build a more complex model and visualize its results.

\`\`\`{r advanced-model} \# Build a multiple regression model model2 \<- lm(body_mass_g \~ bill_length_mm + bill_depth_mm + flipper_length_mm + species + sex, data = penguins_clean)

```{r}
# Build a multiple regression model 

model2 <- lm(body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + species + sex, data = penguins_clean)
```

# Summarize the model

```{r}
summary(model2)
```

# Compare models

```{r}
anova(model1, model2)
```

# Visualize variable importance

```{r}

```

model2_tidy \<- tidy(model2, conf.int = TRUE) %\>% filter(term != "(Intercept)") %\>% mutate( term = str_replace(term, "species", "Species: "), term = str_replace(term, "sex", "Sex: "), abs_estimate = abs(estimate), significance = ifelse(p.value \< 0.001, "p \< 0.001", ifelse(p.value \< 0.01, "p \< 0.01", ifelse(p.value \< 0.05, "p \< 0.05", "Not Significant"))) )

ggplot(model2_tidy, aes(x = reorder(term, abs_estimate), y = estimate, fill = significance)) + geom_col() + geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) + coord_flip() + labs(
